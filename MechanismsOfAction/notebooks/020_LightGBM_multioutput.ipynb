{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost - Multilabel Classification\n",
    "\n",
    "This notebook uses LightGBM and scikit-learn's [MultiOutputClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) to frame the problem as 206 separate binary classification tasks.\n",
    "\n",
    "**Pros**:\n",
    "- Simple - can use any binary classification model.\n",
    "\n",
    "**Cons**:\n",
    "- Doesn't consider any correlations between the different labels.\n",
    "- Slow - have to train 206 separate models (in this case: 1030 models because of the five folds).\n",
    "\n",
    "[Source kernel](https://www.kaggle.com/fchmiel/xgboost-baseline-multilabel-classification)\n",
    "[Source kernel](https://www.kaggle.com/nroman/moa-lightgbm-206-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/moa/lib/python3.8/site-packages/lightgbm/__init__.py:42: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  warnings.warn(\"Starting from version 2.2.1, the library file in distribution wheels for macOS \"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport numpy, matplotlib, pandas, category_encoders, sklearn, xgboost\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from category_encoders import CountEncoder\n",
    "from datetime import datetime\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "\n",
    "from src.data.make_dataset import get_base_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"../style.mplstyle\")\n",
    "SEED = 42\n",
    "NFOLDS = 5\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "- `df`: feature data.\n",
    " - 772 gene expression features and 100 cell viability features. Also:\n",
    "   - `cp_type`: indicates whether the experiment is a treatment (contains drug) or a control (contains no drug - probably DMSO, which has negligible biological effects).\n",
    "   - `cp_dose`: the dose level used in the experiment. Generally, higher dose leads to stronger effect.\n",
    "   - `cp_time`: time elapsed between adding the drug and taking the measurement.\n",
    "   - `flag`: specifies if row is training (n=23,814) or test (n=3,982) data.\n",
    " - One row = one drug at a specific dose (high/low) and time point (24/48/72 hours) (`sig_id`). 5000 unique drugs in total, with ~6 records each (no column that links the records).\n",
    "- `df_tts`: 206 binary target mechanisms for the 23,814 training drugs.\n",
    "- `df_ttn`: 402 additional unscored targets for the 23,814 training drugs for model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 877) (3982, 877) (23814, 403) (23814, 207)\n"
     ]
    }
   ],
   "source": [
    "df, df_ttn, df_tts = get_base_datasets()\n",
    "print(\n",
    "    df.query('flag==\"train\"').shape,\n",
    "    df.query('flag==\"test\"').shape,\n",
    "    df_ttn.shape,\n",
    "    df_tts.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.query('flag==\"train\"').iloc[:, 1:-1]\n",
    "X_test = df.query('flag==\"test\"').iloc[:, 1:-1]\n",
    "y = df_tts.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With LightGBM, minimal pre-processing is necessary. Just encode the two categorical columns (given that they each consist of only two values, any type of encoding is fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = MultiOutputClassifier(LGBMClassifier())\n",
    "pipe = Pipeline(\n",
    "    [(\"encode\", CountEncoder(cols=[0, 2], return_df=False)), (\"classify\", lgb)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following hyperparameters have been taken from another problem (they aren't optimal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"classify__estimator__num_leaves\": 491,\n",
    "    \"classify__estimator__min_child_weight\": 0.03,\n",
    "    \"classify__estimator__feature_fraction\": 0.3,\n",
    "    \"classify__estimator__bagging_fraction\": 0.4,\n",
    "    \"classify__estimator__min_data_in_leaf\": 106,\n",
    "    \"classify__estimator__objective\": \"binary\",\n",
    "    \"classify__estimator__max_depth\": -1,\n",
    "    \"classify__estimator__learning_rate\": 0.01,\n",
    "    \"classify__estimator__boosting_type\": \"gbdt\",\n",
    "    \"classify__estimator__bagging_seed\": 11,\n",
    "    \"classify__estimator__metric\": \"binary_logloss\",\n",
    "    \"classify__estimator__verbosity\": 0,\n",
    "    \"classify__estimator__reg_alpha\": 0.4,\n",
    "    \"classify__estimator__reg_lambda\": 0.6,\n",
    "    \"classify__estimator__random_state\": 47,\n",
    "}\n",
    "\n",
    "_ = pipe.set_params(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, we elect to ignore all control rows (`cp_type==\"ctl_vehicle\"`). Later, we predict all zeros for control rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0 - elapsed time: 0.0 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/moa/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 - elapsed time: 8.9 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/moa/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2 - elapsed time: 17.2 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/moa/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 3 - elapsed time: 25.6 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/moa/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4 - elapsed time: 34.1 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/moa/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed. Total elapsed time: 42.5 mins\n",
      "OOF losses: ['0.017037', '0.017113', '0.016950', '0.016995', '0.017307']\n",
      "Mean OOF (STD) loss across folds: 0.017081 (0.000125)\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "oof_preds = np.zeros(y.shape)\n",
    "test_preds = np.zeros((X_test.shape[0], y.shape[1]))\n",
    "oof_losses = []\n",
    "kf = KFold(n_splits=NFOLDS)\n",
    "for fn, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"Fold: {fn} - elapsed time: {(time()-start)/60:.1f} mins\")\n",
    "    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[trn_idx], y[val_idx]\n",
    "\n",
    "    ctl_mask = (X_train.iloc[:, 0] == \"ctl_vehicle\").values\n",
    "    X_train = X_train[~ctl_mask]\n",
    "    y_train = y_train[~ctl_mask]\n",
    "\n",
    "    pipe.fit(X_train.values, y_train)\n",
    "    val_preds = pipe.predict_proba(X_val.values)  # list of preds per class\n",
    "    val_preds = np.array(val_preds)[:, :, 1].T  # take the positive class results only\n",
    "    oof_preds[val_idx] = val_preds\n",
    "\n",
    "    loss = log_loss(np.ravel(y_val), np.ravel(val_preds))\n",
    "    oof_losses.append(loss)\n",
    "    preds = pipe.predict_proba(X_test.values)\n",
    "    preds = np.array(preds)[:, :, 1].T  # take the positive class results only\n",
    "    test_preds += preds / NFOLDS\n",
    "\n",
    "\n",
    "print(f\"Completed. Total elapsed time: {(time()-start)/60:.1f} mins\")\n",
    "print(f\"OOF losses: {[str(l)[:8] for l in oof_losses]}\")\n",
    "print(\n",
    "    f\"Mean OOF (STD) loss across folds: {np.mean(oof_losses):.6f} ({np.std(oof_losses):.6f})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss: 0.016869\n"
     ]
    }
   ],
   "source": [
    "# set control train preds to 0\n",
    "control_mask = df.query('flag==\"train\"')[\"cp_type\"] == \"ctl_vehicle\"\n",
    "oof_preds[control_mask] = 0\n",
    "\n",
    "print(f\"OOF log loss: {log_loss(np.ravel(y), np.ravel(oof_preds)):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set control test preds to 0\n",
    "control_mask = X_test[\"cp_type\"] == \"ctl_vehicle\"\n",
    "test_preds[control_mask] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../data/raw/sample_submission.csv\")\n",
    "sub.iloc[:, 1:] = test_preds\n",
    "t = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "sub.to_csv(f\"../data/submissions/LightGBM_{t}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
